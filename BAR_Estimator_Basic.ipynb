{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0bd302",
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "SAFEP_parse.py contains all the functions and library calls necessary to run the notebook\n",
    "# Required libraries:\n",
    "- numpy\n",
    "- pandas\n",
    "- matplotlib\n",
    "- alchemlyb (pip install git+https://github.com/alchemistry/alchemlyb)\n",
    "- natsort (for sorting file names)\n",
    "- glob (for unix-like file paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28c611cf-9400-4bbe-b8c1-fe4b8d66ab73",
   "metadata": {},
   "source": [
    "# IMPORTANT: Make sure the temperature (set below) matches the temperature you used to run the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AFEP_parse import *\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/Users/ezry/Downloads/POGE_2/'\n",
    "#path='/u2/home_u2/ems363/Documents/ELIC_DCDs_Analyses/PCPG31/POGE_2/'\n",
    "#path='/path/to/output/files'\n",
    "filename='PO*.fepout'\n",
    "fepoutFiles = glob(path+filename)\n",
    "temperature = 303.15\n",
    "RT = 0.00198720650096 * temperature # ca. 0.59kcal/mol\n",
    "totalSize = 0\n",
    "for file in fepoutFiles:\n",
    "    totalSize += os.path.getsize(file)\n",
    "print(f\"Will process {len(fepoutFiles)} fepout files.\\nTotal size:{np.round(totalSize/10**9, 2)}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3aa52-17f1-44fc-afd8-dfda2787cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fepoutFiles = natsorted(fepoutFiles)\n",
    "maxSize = 10**9 #Don't use the alchemlyb parser if larger than this size. (bytes)\n",
    "decorrelate = False #Flag for decorrelation of samples\n",
    "detectEQ = False #Flag for automated equilibrium detection\n",
    "DiscrepancyFitting = 'LS' #ML = fit PDF of discrepancies with a normal distribution maximum likelihood estimator. LS = fit CDF of discrepancies with a normal distribution least-squares estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bee8b",
   "metadata": {},
   "source": [
    "# Read Data\n",
    "See Shirts and Chodera (2008) for more details\n",
    "\n",
    "\"Statistically optimal analysis of samples from multiple equilibrium states\" doi: 10.1063/1.2978177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if totalSize < maxSize:\n",
    "    from alchemlyb.preprocessing import subsampling\n",
    "\n",
    "    u_nk = namd.extract_u_nk(fepoutFiles, temperature)\n",
    "    \n",
    "    affix=\"\"\n",
    "    \n",
    "    if decorrelate:\n",
    "        print(\"Decorrelating samples\")\n",
    "        method = 'dE'\n",
    "        affix = f'{affix}_decorrelated_{method}'\n",
    "        groups = u_nk.groupby('fep-lambda')\n",
    "        decorr = pd.DataFrame([])\n",
    "        for key, group in groups:\n",
    "            test = subsampling.decorrelate_u_nk(group, method)\n",
    "            decorr = decorr.append(test)\n",
    "        u_nk = decorr\n",
    "    else:\n",
    "        affix = f'{affix}_unprocessed'\n",
    "    \n",
    "    if detectEQ:\n",
    "        print(\"Detecting Equilibrium\")\n",
    "        affix = f\"{affix}_AutoEquilibrium\"\n",
    "        groups = u_nk.groupby('fep-lambda')\n",
    "        EQ = pd.DataFrame([])\n",
    "        for key, group in groups:\n",
    "            group = group[~group.index.duplicated(keep='first')]\n",
    "            test = subsampling.equilibrium_detection(group, group.dropna(axis=1).iloc[:,-1])\n",
    "            EQ = EQ.append(test)\n",
    "        u_nk = EQ\n",
    "    else:\n",
    "        affix=f\"{affix}_HardEquilibrium\"\n",
    "    \n",
    "\n",
    "else:\n",
    "    print(f\"Warning: The files you are trying to read are quite large. Total size={totalSize}.\\nTry the read, decorrelate, save method in the Expanded version of this notebook or increase the maxSize variable above.\\nIn the future, consider using less frequent sampling (e.g. every 100 steps).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea039c3",
   "metadata": {},
   "source": [
    "# Carry out MBAR Fitting and Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d681247-b508-4940-9622-2650864e2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_nk = u_nk.sort_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = BAR()\n",
    "bar.fit(u_nk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30721156",
   "metadata": {},
   "source": [
    "# Extract key features from the MBAR fitting and get Î”G\n",
    "Note: alchemlyb operates in units of kT by default. We multiply by RT to convert to units of kcal/mol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, l_mid, f, df, ddf, errors = get_BAR(bar)\n",
    "changeAndError = f'\\u0394G = {np.round(f.iloc[-1]*RT, 1)}\\u00B1{np.round(errors[-1], 3)} kcal/mol'\n",
    "print(changeAndError)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51aba3b",
   "metadata": {},
   "source": [
    "# Plot the change in free energy based on MBAR estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac26b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative change in kT\n",
    "plt.errorbar(l, f, yerr=errors, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('DeltaG(lambda) (kT)')\n",
    "plt.title(f'Cumulative dG with accumulated errors {affix}\\n{changeAndError}')\n",
    "plt.savefig(f'{path}dG_cumulative_kT_{affix}.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Cumulative change in kcal/mol\n",
    "\"\"\"\n",
    "plt.errorbar(l, f * RT, yerr=errors*RT, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('DeltaG(lambda)(kcal/mol)')\n",
    "plt.savefig(f'{path}dG_cumulative_kcal_per_mol_{affix}.png', dpi=600)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# Per-window change in kT\n",
    "plt.errorbar(l_mid, df, yerr=ddf, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Delta G per window (kT)')\n",
    "plt.title(f'Per-Window dG with individual errors {affix}')\n",
    "plt.savefig(f'{path}dG_{affix}.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Per-window change in kT\n",
    "\n",
    "plt.errorbar(l[1:-1], np.diff(df), marker='.')\n",
    "plt.xlabel('lambda (L)')\n",
    "plt.ylabel(\"dG'(L)\")\n",
    "plt.title(f'derivative of dG {affix}')\n",
    "plt.savefig(f'{path}dG_prime_{affix}.png', dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f90d8c",
   "metadata": {},
   "source": [
    "# Plot the estimated total change in free energy as a function of simulation time; contiguous subsets starting at t=0 (\"Forward\") and t=end (\"Reverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot(u_nk, l)\n",
    "plt.title(f'Convergence {affix}')\n",
    "plt.savefig(f'{path}convergence_{affix}.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b667ea6-2e22-4396-911b-a3dd7a8ffe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db862c57-7c7b-43cc-b105-51f98a30e687",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = u_nk.groupby('fep-lambda')\n",
    "for key, group in groups:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c00fddf-fdee-4857-a448-842ab4745278",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = group.dropna(axis=1).iloc[slice(None), 0].reset_index().loc[0:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f735f3b0-aa41-4634-b1c1-6516169312f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = correlate(test.iloc[:,2], test.time, mode='same')\n",
    "corr = corr[len(corr)//2:]\n",
    "plt.plot(corr/corr[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6709db",
   "metadata": {},
   "source": [
    "# Use an exponential estimator to assess residual discrepancies and check for hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, l_mid, dG_f, dG_b = get_EXP(u_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b501c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(l_mid, np.zeros(len(l_mid)), dG_f + np.array(dG_b), label=\"fwd - bwd\", linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f'Fwd-bwd discrepancies by lambda {affix}')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Diff. in delta-G')\n",
    "plt.savefig(f'{path}discrepancies_{affix}.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9430c7-a886-4ab8-ac50-de42b7953460",
   "metadata": {},
   "source": [
    "# Estimate and plot the Probability Density Function (PDF) for the differences shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f786fd8b-34a3-49b1-9c88-5b66d20b5e8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "from scipy.optimize import curve_fit as scipyFit\n",
    "from scipy.stats import skew\n",
    "#Wrapper for fitting the normal CDF\n",
    "def cumFn(x, m, s):\n",
    "    r = norm.cdf(x, m, s)\n",
    "    return r\n",
    "\n",
    "def pdfFn(x,m,s):\n",
    "    r = norm.pdf(x,m,s)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88943b75-4c3f-4149-a58a-9284fff9957f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "diff = dG_f + np.array(dG_b)\n",
    "diff.sort()\n",
    "X = diff\n",
    "Y = np.arange(len(X))/len(X)\n",
    "\n",
    "#plot the data\n",
    "fig, (pdfAx, pdfResid) = plt.subplots(2, 1, sharex=True)\n",
    "plt.xlabel('Difference in delta-G')\n",
    "\n",
    "#fit a normal distribution to the existing data\n",
    "if DiscrepancyFitting == 'LS':\n",
    "    fitted = scipyFit(cumFn, X, Y)[0] #Fit norm.cdf to (X,Y)\n",
    "elif DiscrepancyFitting == 'ML':\n",
    "    fitted = norm.fit(X) # fit a normal distribution to X\n",
    "else:\n",
    "    raise(\"Error: Discrepancy fitting code not known. Acceptable values: ML (maximum likelihood) or LS (least squares)\")\n",
    "discrepancies = dG_f + np.array(dG_b)\n",
    "\n",
    "#pdf\n",
    "dx = 0.01\n",
    "\n",
    "binNum = 20\n",
    "pdfY, pdfX = np.histogram(discrepancies, bins=binNum, density=True)\n",
    "pdfX = (pdfX[1:]+pdfX[:-1])/2\n",
    "\n",
    "pdfXnorm  = np.arange(np.min(X), np.max(X), dx)\n",
    "pdfYnorm = norm.pdf(pdfXnorm, fitted[0], fitted[1])\n",
    "\n",
    "pdfYexpected = norm.pdf(pdfX, fitted[0], fitted[1])\n",
    "\n",
    "pdfAx.plot(pdfX, pdfY,  label=\"Estimated Distribution\")\n",
    "pdfAx.set_ylabel(\"PDF\")\n",
    "pdfAx.plot(pdfXnorm, pdfYnorm, label=\"Fitted Normal Distribution\", color=\"orange\")\n",
    "\n",
    "#pdf residuals\n",
    "pdfResiduals = pdfY-pdfYexpected\n",
    "pdfResid.plot(pdfX, pdfResiduals)\n",
    "pdfResid.set_ylabel(\"PDF residuals\") \n",
    "\n",
    "fig.set_figheight(10)\n",
    "if DiscrepancyFitting == 'LS':\n",
    "    pdfAx.title.set_text(f\"Least squares fitting of cdf(fwd-bkwd)\\nSkewness: {np.round(skew(X),2)}\\nFitted parameters: Mean={np.round(fitted[0],3)}, Stdv={np.round(fitted[1],3)}\\nPopulation parameters: Mean={np.round(np.average(X),3)}, Stdv={np.round(np.std(X),3)}\")\n",
    "    plt.savefig(f\"{path}LeastSquares_pdf_{affix}.png\", dpi=600)\n",
    "elif DiscrepancyFitting == 'ML':\n",
    "    pdfAx.title.set_text(f\"Maximum likelihood fitting of fwd-bkwd\\nFitted parameters: Mean={np.round(fitted[0],3)}, Stdv={np.round(fitted[1],3)}\\nPopulation parameters: Mean={np.round(np.average(X),3)}, Stdv={np.round(np.std(X),3)}\")\n",
    "    plt.savefig(f\"{path}MaximumLikelihood_pdf_{affix}.png\", dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018c4da4-d9c9-4503-8633-92b7c7fbf560",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4337224d-b195-4842-9cf8-2c01cab5fd19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2449ab1f-47f0-4b97-990b-9d1d43969a53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
