{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9e99020e-9c25-48b9-8bae-2ec78462ed2a",
   "metadata": {},
   "source": [
    "# This notebook has additional diagnostic tools not usually necessary for well-behaved FEP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "341f4c2c",
   "metadata": {},
   "source": [
    "# Import AFEP_parse and dependencies\n",
    "AFEP_parse.py contains all the functions and library calls necessary to run the notebook\n",
    "\n",
    "# Required modules:\n",
    "- numpy\n",
    "- pandas\n",
    "- matplotlib\n",
    "- alchemlyb (`pip install git+https://github.com/alchemistry/alchemlyb`)\n",
    "- natsort (for sorting file names)\n",
    "- glob (for unix-like file paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AFEP_parse import *\n",
    "from alchemlyb.preprocessing import subsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aae189ca",
   "metadata": {},
   "source": [
    "# User parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "463bb934",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path='/home/ezry/winHome/Documents/ELIC_Data/PCPGPE211/Se'\n",
    "path='/home/ems363/Documents/ELIC_DCDs_Analyses/PCPGPE211/POEG_104_withZ/'\n",
    "filename='PO*.fepout'\n",
    "\n",
    "temperature = 303.15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee77fd0",
   "metadata": {
    "tags": []
   },
   "source": [
    "## IMPORTANT: Make sure the temperature above matches the temperature used to run the simulations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['figure.dpi'] = 150\n",
    "import os\n",
    "\n",
    "RT = 0.00198720650096 * temperature\n",
    "#path='/path/to/output/files'\n",
    "filename='PO*.fepout'\n",
    "fepoutFiles = glob(path+filename)\n",
    "totalSize = 0\n",
    "for file in fepoutFiles:\n",
    "    totalSize += os.path.getsize(file)\n",
    "print(f\"Will process {len(fepoutFiles)} fepout files.\\nTotal size:{np.round(totalSize/10**9, 2)}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3aa52-17f1-44fc-afd8-dfda2787cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fepoutFiles = natsorted(fepoutFiles)\n",
    "maxSize = 10**9 #Don't use the alchemlyb parser if larger than this size. (bytes)\n",
    "decorrelate = True\n",
    "detectEQ = False\n",
    "DiscrepancyFitting = 'LS' #ML = fit PDF of discrepancies with a normal distribution maximum likelihood estimator. LS = fit CDF of discrepancies with a normal distribution least-squares estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bee8b",
   "metadata": {},
   "source": [
    "# Small data sets can be read and decorrelated sequentially, if desired\n",
    "See Shirts and Chodera (2008) for more details\n",
    "\n",
    "\"Statistically optimal analysis of samples from multiple equilibrium states\" doi: 10.1063/1.2978177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if totalSize < maxSize:\n",
    "    u_nk, affix = readAndProcess(fepoutFiles, temperature, decorrelate, detectEQ)\n",
    "    \n",
    "else:\n",
    "    print(f\"Warning: The files you are trying to read are quite large. Total size={totalSize}.\\nTry the read, decorrelate, save method in the Expanded version of this notebook or increase the maxSize variable above.\\nIn the future, consider using less frequent sampling (e.g. every 100 steps).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea039c3",
   "metadata": {},
   "source": [
    "# Carry out MBAR Fitting and Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d681247-b508-4940-9622-2650864e2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_nk = u_nk.sort_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "002929bf-121d-41b5-aa36-d343878ea65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame()\n",
    "for fl in set(u_nk.index.get_level_values(1)):\n",
    "    counts[fl] = u_nk.loc[(slice(None), fl), :].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4380297c-3c93-4d82-8c59-bd70ee31e255",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.signal import correlate\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "from scipy.optimize import curve_fit, leastsq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac7655d2-6248-4ff0-a6d6-bd8e50bca2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getCorr(ser, timeStep):\n",
    "    flucs = ser - np.mean(ser)\n",
    "    valsRaw = correlate(flucs, flucs, mode='same')\n",
    "    steps = ser.index.get_level_values(0)\n",
    "    dt = [0]\n",
    "    dt = np.concatenate(([0], (np.cumsum(steps[1:]-steps[:-1]))))*timeStep\n",
    "    idx = dt[:len(valsRaw)//2]\n",
    "\n",
    "    \n",
    "    try:\n",
    "        valsSplit = valsRaw[len(valsRaw)//2:-1]\n",
    "        corr = pd.Series(valsSplit, index=idx)\n",
    "    except:\n",
    "        valsSplit = valsRaw[len(valsRaw)//2:]\n",
    "        corr = pd.Series(valsSplit, index=idx)\n",
    "    return corr/np.max(corr)\n",
    "\n",
    "def my_exp(t, K):\n",
    "    return np.exp(-K * t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd6b31d-675e-4340-aea4-68b5b8a88818",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate decay times in ps\n",
    "groups = u_nk.groupby('fep-lambda')\n",
    "decayTimes = pd.DataFrame()\n",
    "sampling = pd.DataFrame()\n",
    "for key, group in groups:\n",
    "    trimmed = group.dropna(axis=1)\n",
    "    for col in trimmed:\n",
    "        if col != key:\n",
    "            ser = trimmed[col]\n",
    "            corr = getCorr(ser, timeStep=0.002)\n",
    "            [K], _ = sp.optimize.curve_fit(my_exp, corr.index, corr.values, maxfev=1000)\n",
    "            decayTimes.loc[key, col] = 1/K\n",
    "            sampling.loc[key, col] = corr.index[1]-corr.index[0]\n",
    "sampling = sampling.sort_index(axis=0).sort_index(axis=1).copy()\n",
    "decayTimes = decayTimes.sort_index(axis=0).sort_index(axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "245dc48e-bfa4-4bd4-8fc7-3ad926db45b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fwdDecay = pd.Series(np.diagonal(decayTimes, offset=1), index=decayTimes.index[:-1])\n",
    "bwdDecay = pd.Series(np.diagonal(decayTimes, offset=-1), index=decayTimes.index[1:])\n",
    "fwdSmpl = pd.Series(np.diagonal(sampling, offset=1), index=sampling.index[:-1])\n",
    "bwdSmpl = pd.Series(np.diagonal(sampling, offset=-1), index=sampling.index[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a911a1b-a6dd-40f3-bf19-82c69923854f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(bwdDecay, label='Backward Characteristic Decay', color='orange')\n",
    "plt.plot(bwdSmpl, label='Backward Sampling Period', linestyle='-.', color='orange')\n",
    "plt.plot(fwdDecay, label='Forward Characteristic Decay', color='blue')\n",
    "plt.plot(fwdSmpl, label='Forward Sampling Period', linestyle='--', color='blue' )\n",
    "\n",
    "plt.ylabel('Time (ps)')\n",
    "plt.xlabel(r'$\\lambda$')\n",
    "plt.legend()\n",
    "#plt.savefig(f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = BAR()\n",
    "bar.fit(u_nk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30721156",
   "metadata": {},
   "source": [
    "# Extract key features from the MBAR fitting and get Î”G\n",
    "Note: alchemlyb operates in units of kT by default. We multiply by RT to conver to units of kcal/mol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, l_mid, f, df, ddf, errors = get_BAR(bar)\n",
    "changeAndError = f'\\u0394G = {np.round(f.iloc[-1]*RT, 1)}\\u00B1{np.round(errors[-1], 3)} kcal/mol'\n",
    "print(changeAndError)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51aba3b",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Plot the change in free energy based on MBAR estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac26b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative change in kT\n",
    "plt.errorbar(l, f, yerr=errors, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('DeltaG(lambda) (kT)')\n",
    "plt.title(f'Cumulative dG with accumulated errors {affix}\\n{changeAndError}')\n",
    "plt.savefig(f'{path}dG_cumulative_kT_{affix}.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Cumulative change in kcal/mol\n",
    "\"\"\"\n",
    "plt.errorbar(l, f * RT, yerr=errors*RT, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('DeltaG(lambda)(kcal/mol)')\n",
    "plt.savefig(f'{path}dG_cumulative_kcal_per_mol_{affix}.png', dpi=600)\n",
    "plt.show()\n",
    "\"\"\"\n",
    "# Per-window change in kT\n",
    "plt.errorbar(l_mid, df, yerr=ddf, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Delta G per window (kT)')\n",
    "plt.title(f'Per-Window dG with individual errors {affix}')\n",
    "plt.savefig(f'{path}dG_{affix}.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Per-window change in kT\n",
    "\n",
    "plt.errorbar(l[1:-1], np.diff(df), marker='.')\n",
    "plt.xlabel('lambda (L)')\n",
    "plt.ylabel(\"dG'(L)\")\n",
    "plt.title(f'derivative of dG {affix}')\n",
    "plt.savefig(f'{path}dG_prime_{affix}.png', dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f90d8c",
   "metadata": {},
   "source": [
    "# Plot the estimated total change in free energy as a function of simulation time; contiguous subsets starting at t=0 (\"Forward\") and t=end (\"Reverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot(u_nk, l)\n",
    "plt.title(f'Convergence {affix}')\n",
    "plt.savefig(f'{path}convergence_{affix}.png', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7948bf74-b3be-4ff5-89aa-849d1d0eff60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58339e96-2ec0-4da6-a7d8-58e0ef549f73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d264d4b-b7aa-4265-92b5-71fbda2306a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for bootstrapping estimates and generating confidence intervals\n",
    "def bootStrapEstimate(u_nk, estimator='BAR', iterations=100, schedule=[10,20,30,40,50,60,70,80,90,100]):\n",
    "    groups = u_nk.groupby('fep-lambda')\n",
    "\n",
    "    if estimator == 'EXP':\n",
    "        dGfs = {}\n",
    "        dGbs = {}\n",
    "        means = {}\n",
    "    elif estimator == 'BAR':\n",
    "        dGs = {}\n",
    "        errs = {}\n",
    "    else:\n",
    "        raise ValueError(f\"unknown estimator: {estimator}\")\n",
    "\n",
    "    for p in schedule:\n",
    "        Fs = []\n",
    "        Bs = []\n",
    "        fs = []\n",
    "        Gs = []\n",
    "        #rs = []\n",
    "        for i in np.arange(iterations):\n",
    "            sampled = pd.DataFrame([])\n",
    "            for key, group in groups:\n",
    "                N = int(p*len(group)/100)\n",
    "                if N < 1:\n",
    "                    N=1\n",
    "                rows = np.random.choice(len(group), size=N)\n",
    "                test = group.iloc[rows,:]\n",
    "                sampled = pd.concat([sampled, test])\n",
    "            if estimator == 'EXP':\n",
    "                l, l_mid, dG_f, dG_b = get_EXP(pd.DataFrame(sampled))\n",
    "                F = np.sum(dG_f)\n",
    "                B = np.sum(-dG_b)\n",
    "                Fs.append(F)\n",
    "                Bs.append(B)\n",
    "                Gs.append(np.mean([F,B]))\n",
    "            elif estimator == 'BAR':\n",
    "                tmpBar = BAR()\n",
    "                tmpBar.fit(sampled)\n",
    "                l, l_mid, f, df, ddf, errors = get_BAR(tmpBar)\n",
    "                fs.append(f.values[-1])\n",
    "                #rs.append(errors[-1])\n",
    "\n",
    "        if estimator == 'EXP':\n",
    "            dGfs[p] = Fs\n",
    "            dGbs[p] = Bs\n",
    "            means[p] = Gs\n",
    "        else:\n",
    "            dGs[p] = fs\n",
    "            #errs[p] = rs\n",
    "\n",
    "    if estimator == 'EXP':\n",
    "        fwd = pd.DataFrame(dGfs).melt().copy()\n",
    "        bwd = pd.DataFrame(dGbs).melt().copy()\n",
    "        alldGs = pd.concat([fwd, bwd])\n",
    "        means = pd.DataFrame(means).melt().copy()\n",
    "        return (alldGs, fwd, bwd, means)\n",
    "    else:\n",
    "        alldGs = pd.DataFrame(dGs).melt().copy()\n",
    "        #allErrors = pd.DataFrame(errs).melt().copy()\n",
    "        return alldGs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88ceb61-966c-43d6-b552-7c385890df97",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from warnings import simplefilter \n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "estimator = 'EXP'\n",
    "iterations = 100\n",
    "schedule = tqdm([1, 10, 25, 50, 75, 100])\n",
    "if estimator == 'BAR':\n",
    "    alldGs = bootStrapEstimate(u_nk, estimator, iterations, schedule)\n",
    "elif estimator == 'EXP':\n",
    "    alldGs, fwd, bwd, means  = bootStrapEstimate(u_nk, estimator, iterations, schedule)\n",
    "else:\n",
    "    raise(f'Error: estimator {estimator} not known')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031f4032-81f7-42af-a173-65a5e6b821d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if estimator=='EXP':\n",
    "    fwd = fwd.set_index('variable')\n",
    "    bwd = bwd.set_index('variable')\n",
    "alldGs = alldGs.set_index('variable')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84083ef-757a-4e0b-bbf8-090a94ddd2ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "interval=0.95\n",
    "upper, lower, means = getEmpiricalCI(alldGs, interval)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39ebc070-7f9b-4a8e-a2ed-f203293dbd3d",
   "metadata": {},
   "source": [
    "upper, lower, means = getLimits(alldGs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bae9378-043d-4e1a-a040-4b2c378b55fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convergence_plot(u_nk, l)\n",
    "#plt.plot(keys, upper, color='gray')\n",
    "#plt.plot(keys, lower, color='gray')\n",
    "keys = np.sort(list(set(alldGs.index)))\n",
    "plt.fill_between(keys/100, upper, lower, color='gray', alpha=0.3, label=f\"{interval*100}% confidence interval\")\n",
    "plt.plot(keys/100, means)\n",
    "if estimator == 'EXP':\n",
    "    plt.scatter(fwd.index/100, fwd.value, label='Forward Samples', s=2)\n",
    "    plt.scatter(bwd.index/100, bwd.value, label='Backward Samples', s=2)\n",
    "else:\n",
    "    plt.scatter(alldGs.index/100, alldGs.value, label='BAR Estimates', s=2)\n",
    "plt.legend()\n",
    "plt.ylabel(\"Net dG (kT)\")\n",
    "plt.xlabel(\"Percent of data used\")\n",
    "\n",
    "plt.title(f'Bootstrapped Estimate: {np.round(means[-1]*RT,1)} +/- {np.round((upper[-1]-means[-1])*RT,1)}kcal/mol')\n",
    "\n",
    "plt.savefig(f'{path}/convergence_{estimator}_{iterations}_{affix}.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "094a8882-51af-44aa-a77d-8bcf40f00a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "nbins = 10\n",
    "if estimator == 'EXP':\n",
    "    fvals, fbins, _ = plt.hist(fwd.loc[100], label='forward', bins=nbins, histtype='step')\n",
    "    bvals, bbins, _ = plt.hist(bwd.loc[100], label='backward', bins=nbins, histtype='step')\n",
    "    plt.plot(np.mean([fbins[1:], fbins[:-1]], axis=0), fvals)\n",
    "    plt.plot(np.mean([bbins[1:], bbins[:-1]], axis=0), bvals)\n",
    "    vals, bins, _ = plt.hist(alldGs.loc[100], label='Combined', bins=nbins, histtype='step')\n",
    "    plt.plot(np.mean([bins[1:], bins[:-1]], axis=0), vals)\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{path}/distribution_of_bootstrapped_samples_{estimator}_{iterations}_{affix}.pdf')\n",
    "else:\n",
    "    vals, bins, _ = plt.hist(alldGs.loc[100], label='BAR', bins=nbins)\n",
    "    plt.plot(np.mean([bins[1:], bins[:-1]], axis=0), vals)\n",
    "    plt.xlabel('dG in reduced units')\n",
    "    plt.legend()\n",
    "    plt.savefig(f'{path}/distribution_of_bootstrapped_samples_{estimator}_{iterations}_{affix}.pdf')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6709db",
   "metadata": {},
   "source": [
    "# Use an exponential estimator to assess residual discrepancies and check for hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, l_mid, dG_f, dG_b = get_EXP(u_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b501c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyst = dG_f + np.array(dG_b)\n",
    "plt.vlines(l_mid, np.zeros(len(l_mid)), hyst*RT, label=\"fwd - bwd\", linewidth=2)\n",
    "plt.ylim(-1,1)\n",
    "plt.plot(l_mid, hyst*RT, linewidth=1)\n",
    "plt.ylim(-1,1)\n",
    "plt.title(f'Fwd-bwd discrepancies by lambda {affix}')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Diff. in delta-G (kcal/mol)')\n",
    "plt.savefig(f'{path}discrepancies_{affix}.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e9430c7-a886-4ab8-ac50-de42b7953460",
   "metadata": {},
   "source": [
    "# OPTIONAL: Estimate and plot the Cumulative Density function (CDF) for the differences shown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecb0a342-631f-41f2-9924-6efb2878c3e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import erfc\n",
    "from scipy.optimize import curve_fit as scipyFit\n",
    "from scipy.stats import skew\n",
    "#Wrapper for fitting the normal CDF\n",
    "def cumFn(x, m, s):\n",
    "    r = norm.cdf(x, m, s)\n",
    "    return r\n",
    "\n",
    "def pdfFn(x,m,s):\n",
    "    r = norm.pdf(x,m,s)\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6556861-71ed-46ac-90f9-6ce63c700662",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = dG_f + np.array(dG_b)\n",
    "diff.sort()\n",
    "X = diff*RT\n",
    "Y = np.arange(len(X))/len(X)\n",
    "\n",
    "#fit a normal distribution to the existing data\n",
    "#fitted = norm.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88943b75-4c3f-4149-a58a-9284fff9957f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#fit a normal distribution to the existing data\n",
    "\n",
    "if DiscrepancyFitting == 'LS':\n",
    "    fitted = scipyFit(cumFn, X, Y)[0] #Fit norm.cdf to (X,Y)\n",
    "elif DiscrepancyFitting == 'ML':\n",
    "    #fitted = scipyFit(pdfFn, X, Y)[0]\n",
    "    fitted = norm.fit(X) # fit a normal distribution to X\n",
    "else:\n",
    "    raise(\"Error: Discrepancy fitting code not known. Acceptable values: ML or LS\")\n",
    "discrepancies = X\n",
    "\n",
    "dx = 0.01\n",
    "cdfXnorm  = np.arange(np.min(X), np.max(X), dx)\n",
    "cdfYnorm = norm.cdf(cdfXnorm, fitted[0], fitted[1])\n",
    "cdfYexpected = norm.cdf(X, fitted[0], fitted[1])\n",
    "\n",
    "#plot the data as they are (estimate the CDF) and the fitted cdf\n",
    "fig, (cdfAx, cdfResid, pdfAx, pdfResid) = plt.subplots(4, 1, sharex=True)\n",
    "plt.xlabel('Difference in delta-G')\n",
    "\n",
    "cdfAx.scatter(X, Y, 2, label=\"Fwd bkd differences\")\n",
    "cdfAx.plot(cdfXnorm, cdfYnorm, label=\"Normal Distribution\", color=\"orange\")\n",
    "cdfAx.set_ylabel(\"CDF\")\n",
    "cdfAx.legend()\n",
    "\n",
    "#cdf Residuals\n",
    "cdfResiduals = Y-cdfYexpected\n",
    "cdfResid.plot(X, cdfResiduals)\n",
    "cdfResid.set_ylabel(\"CDF residuals\")\n",
    "\n",
    "#pdf\n",
    "dx = 0.01\n",
    "dx = 0.01\n",
    "\n",
    "binNum = 20\n",
    "window = binNum\n",
    "pdfY, pdfX = np.histogram(discrepancies, bins=binNum, density=True)\n",
    "pdfX = (pdfX[1:]+pdfX[:-1])/2\n",
    "\n",
    "pdfXnorm  = np.arange(np.min(X), np.max(X), dx)\n",
    "pdfYnorm = norm.pdf(pdfXnorm, fitted[0], fitted[1])\n",
    "\n",
    "pdfYexpected = norm.pdf(pdfX, fitted[0], fitted[1])\n",
    "\n",
    "pdfAx.plot(pdfX, pdfY,  label=\"Estimated Distribution\")\n",
    "pdfAx.set_ylabel(\"PDF\")\n",
    "pdfAx.plot(pdfXnorm, pdfYnorm, label=\"Fitted Normal Distribution\", color=\"orange\")\n",
    "\n",
    "#pdf residuals\n",
    "pdfResiduals = pdfY-pdfYexpected\n",
    "pdfResid.plot(pdfX, pdfResiduals)\n",
    "pdfResid.set_ylabel(\"PDF residuals\") \n",
    "\n",
    "\n",
    "fig.set_figheight(10)\n",
    "if DiscrepancyFitting == 'LS':\n",
    "    cdfAx.title.set_text(f\"Least squares fitting of cdf(fwd-bkwd)\\nSkewness: {np.round(skew(X),2)}\\nFitted parameters: Mean={np.round(fitted[0],3)}, Stdv={np.round(fitted[1],3)}\\nPopulation parameters: Mean={np.round(np.average(X),3)}, Stdv={np.round(np.std(X),3)}\")\n",
    "    plt.savefig(f\"{path}LeastSquaresCDF{affix}.png\", dpi=600)\n",
    "elif DiscrepancyFitting == 'ML':\n",
    "    cdfAx.title.set_text(f\"Maximum likelihood fitting of fwd-bkwd\\nFitted parameters: Mean={np.round(fitted[0],3)}, Stdv={np.round(fitted[1],3)}\\nPopulation parameters: Mean={np.round(np.average(X),3)}, Stdv={np.round(np.std(X),3)}\")\n",
    "    plt.savefig(f\"{path}MaximumLikelihood{affix}.png\", dpi=600)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60caa0-e27d-4a1d-98aa-d475364de9a5",
   "metadata": {},
   "source": [
    "# OPTIONAL DIAGNOSTICS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5e15321-ec66-446e-bb59-1b73e8a3dca3",
   "metadata": {},
   "source": [
    "# For looking at FEP data as a time series. Can be useful diagnostically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f883b1c-6714-4394-8871-d44f5801ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "forwardMask = u_nk.copy()\n",
    "offset = u_nk.columns[1] - u_nk.columns[0]\n",
    "\n",
    "for col in forwardMask.columns:\n",
    "    forwardMask[col].values[:] = 0\n",
    "\n",
    "for x in set(u_nk.index.get_level_values(1)):\n",
    "    forwardMask.loc[(slice(None),x),np.round(x+offset, 3)] = True\n",
    "\n",
    "forwardMask = forwardMask.dropna(axis=1)\n",
    "\n",
    "backwardMask = u_nk.copy()\n",
    "offset = u_nk.columns[1] - u_nk.columns[0]\n",
    "\n",
    "for col in backwardMask.columns:\n",
    "    backwardMask[col].values[:] = 0\n",
    "\n",
    "for x in set(u_nk.index.get_level_values(1)):\n",
    "    backwardMask.loc[(slice(None),x),np.round(x+offset, 3)] = True\n",
    "\n",
    "backwardMask = backwardMask.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd2f15ae-53a2-427e-a49f-8f4df1d435b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_nk.mask(forwardMask.astype(bool))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ce074ce-b1fe-4191-ab67-e34abe15d817",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.round(0.025*11, 3)\n",
    "l2 = np.round(0.025*12, 3)\n",
    "forward = u_nk.loc[(slice(None), l), l2]\n",
    "plt.plot(forward.index.get_level_values(0), forward, label=\"forward\")\n",
    "reverse = -1*u_nk.loc[(slice(None), l2), l]\n",
    "plt.plot(reverse.index.get_level_values(0), reverse, label=\"reverse\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a13340-251e-475c-b649-13356aeeba51",
   "metadata": {},
   "outputs": [],
   "source": [
    "histF, edgesF = np.histogram(forward, density=True)\n",
    "histR, edgesR = np.histogram(reverse, density=True)\n",
    "\n",
    "plt.plot(np.mean([edgesF[1:], edgesF[:-1]], axis=0), histF, label =\"forward\")\n",
    "plt.plot(np.mean([edgesR[1:], edgesR[:-1]], axis=0), histR, label=\"backward\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412d3d02-6cc1-413e-b151-71cc40626446",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(l_mid, dG_f)\n",
    "plt.plot(l_mid, -dG_b)\n",
    "plt.title(f\"fwd and -bwd exponential estimations {affix}\")\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(\"dG\")\n",
    "plt.savefig(f\"{path}exponentials.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "402caa17-f217-4413-af60-e698ee892601",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(l_mid, np.cumsum(dG_f))\n",
    "plt.plot(l_mid, -np.cumsum(dG_b))\n",
    "plt.title(f\"fwd and -bwd exponential estimations {affix}\")\n",
    "plt.xlabel(\"lambda\")\n",
    "plt.ylabel(\"dG\")\n",
    "plt.savefig(f\"{path}exponentials_cumulative_{affix}.png\", dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa8a5af-e8ec-4cce-9965-416fad6dd6ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the exponential estimator to estimate an error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7b8ec25-5e22-4099-bb2d-c2ed54e337bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f593d40-8d97-43f7-ab54-aad8a2832c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "errors = []\n",
    "for i in np.arange(len(dG_f)):\n",
    "    errors.append(scipy.stats.sem([dG_f[i], -dG_b[i]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37acba20-2eae-4bb2-91a1-e136936ef119",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm(errors, ord=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c2c67e-b2fb-4e4e-9533-1f9d8516dbc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 0\n",
    "for x in errors:\n",
    "    total += x**2\n",
    "np.sqrt(total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eb664f9-e0a6-43ca-bc75-a3902a5dbaee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea747289-27ab-40cf-bd4b-43c0509f5828",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bdeb329c-4760-48b1-9c3f-54364adb54c1",
   "metadata": {},
   "source": [
    "# Alternative measure of hysteresis: Two-sample Bootstrap for forward/backward samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9c0491f-7f01-43ed-85d3-91b8c1bdc1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def diffMeans(X1, X2):\n",
    "    return np.mean(X2)-np.mean(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d75eea80-a09e-4d89-b58b-4dee893d845a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x1 and x2 should be numpy list-like data series\n",
    "#nReps: the number of bootstrapped samples to make\n",
    "#measure: a function that takes two list-likes and returns a single metric\n",
    "#H0: the value of the null hypothesis (e.g. 0)\n",
    "\n",
    "def TwoSampleBS(x1, x2, nReps, measure, H0):\n",
    "    bootstrapStats = np.zeros(nReps)\n",
    "    n1 = len(x1)\n",
    "    n2 = len(x2)\n",
    "    for i in np.arange(len(bootstrapStats)):\n",
    "        sampX1 = x1[np.random.randint(0,n1,n1)]\n",
    "        sampX2 = x2[np.random.randint(0,n2,n2)]\n",
    "        bootstrapStats[i] = measure(sampX1, sampX2)\n",
    "        \n",
    "    pvalue = np.sum(bootstrapStats < H0)/nReps\n",
    "    if (pvalue>0.5):\n",
    "        pvalue = 1-pvalue\n",
    "        \n",
    "    return bootstrapStats, pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17a0cb50-7593-49da-a23a-5830e1774923",
   "metadata": {},
   "outputs": [],
   "source": [
    "series0 = u_nk.iloc[:,0].dropna()\n",
    "series1 = u_nk.iloc[:,1].dropna()\n",
    "series0 = series0[series0 != 0]\n",
    "series0 = series0.loc[(slice(None),series0.index[0][1])]\n",
    "series1 = series1[series1 != 0]\n",
    "series1 = series1.loc[(slice(None),series1.index[0][1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d536855-05a7-4e72-a9fd-1f8096cbfb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = u_nk.groupby('fep-lambda')\n",
    "#fig, axes = plt.subplots(ncols=len(groups))\n",
    "fig, axes = plt.subplots(1)\n",
    "flierprops = dict(marker='.', markerfacecolor='green', markersize=3, linestyle=None, markeredgecolor='green')\n",
    "i = -1\n",
    "for key, group in groups:\n",
    "    i=i+1\n",
    "    ax = axes\n",
    "    ax.boxplot(group[group!=0].dropna(axis=1).iloc[:,0], showfliers=False, flierprops=flierprops)\n",
    "    #if i > 0:\n",
    "        #ax.set_xticks([])\n",
    "        #ax.set_yticks([])\n",
    "        #ax.axis('off')\n",
    "    try: \n",
    "        ax.boxplot(group[group!=0].dropna(axis=1).iloc[:,1], showfliers=False, flierprops=flierprops)\n",
    "    except:\n",
    "        continue\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed362403-7e89-4715-b54b-9a9c252d7d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "import seaborn as sns\n",
    "groups = u_nk.groupby('fep-lambda')\n",
    "\n",
    "for key, group in groups:\n",
    "    sns.boxplot(x=group[group!=0].dropna(axis=1).iloc[:,0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b0d1f2-385e-40ed-a5fd-fafb2e8017fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "group[group!=0].dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c57d7fd-90bd-4a8d-a2d9-09d67b729358",
   "metadata": {},
   "outputs": [],
   "source": [
    "nReps=1000\n",
    "\n",
    "bootstrapStats, pvalue = TwoSampleBS(np.array(-series0), np.array(series1), nReps, diffMeans, 0)\n",
    "\n",
    "vals, bins = np.histogram(bootstrapStats, bins=50, density=True)\n",
    "centers = (bins[1:]+bins[:-1])/2\n",
    "plt.plot(centers, vals/np.max(vals))\n",
    "cdf = np.arange(len(bootstrapStats))/nReps\n",
    "plt.plot(np.sort(bootstrapStats), cdf)\n",
    "plt.title(f'P-value: {np.round(pvalue*100,0)}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e4c8cc-7f07-4623-a9bf-90ac11ed9f42",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d53db2-45ad-46e9-b958-1fb76f89c7ad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "86bb2766",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "none\t3:1 PC:PG\tC\tE\tAS\t1\trunning\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# For large data sets: read, decorrelate, save\n",
    "This reduces RAM requirements between reading and decorrelating\n",
    "\n",
    "Remember: pickles are not future-proof and should not be used for long-term data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345a68f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if totalSize>maxSize:\n",
    "    method = 'dE'\n",
    "    affix = f'decorrelated_{method}'\n",
    "\n",
    "    pickles = []\n",
    "    idx = 0\n",
    "\n",
    "    for file in tqdm(fepoutFiles):\n",
    "        df = readFiles([file])\n",
    "        u_nk = u_nk_fromDF(df, temperature, 0, warnings=False)\n",
    "\n",
    "        groups = u_nk.groupby('fep-lambda')\n",
    "        decorr = pd.DataFrame([])\n",
    "        for key, group in groups:\n",
    "            test = subsampling.decorrelate_u_nk(group, method)\n",
    "            decorr = decorr.append(test)\n",
    "        u_nk = decorr\n",
    "        pickle = f\"{path}{affix}{idx:03d}.pkl\"\n",
    "        u_nk.to_pickle(pickle)\n",
    "        pickles.append(pickle)\n",
    "        idx +=1\n",
    "        \n",
    "    pickleDFs = []\n",
    "    for pickle in pickles:\n",
    "        pickleDFs.append(pd.read_pickle(pickle))\n",
    "\n",
    "    u_nk = pd.concat(pickleDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812ebef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#u_nk = u_nk.drop(0.975, axis=1) #to remove incomplete windows e.g. when changing lambda resolutions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
