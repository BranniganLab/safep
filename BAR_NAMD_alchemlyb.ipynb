{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd0bd302",
   "metadata": {},
   "source": [
    "# Import necessary libraries\n",
    "SAFEP_parse.py contains all the functions and library calls necessary to run the notebook\n",
    "# Required libraries:\n",
    "- numpy\n",
    "- pandas\n",
    "- matplotlib\n",
    "- alchemlyb (pip install git+https://github.com/alchemistry/alchemlyb)\n",
    "- natsort (for sorting file names)\n",
    "- glob (for unix-like file paths)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708b4d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from AFEP_parse import *\n",
    "plt.rcParams['figure.dpi'] = 150"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb1e9b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210c2d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "path='/home/ems363/Documents/ELIC/211/replicaC/'\n",
    "filename='*.fep*'\n",
    "fepoutFiles = glob(path+filename)\n",
    "temperature = 300\n",
    "RT = 0.00198720650096 * temperature # ca. 0.59kcal/mol\n",
    "totalSize = 0\n",
    "for file in fepoutFiles:\n",
    "    totalSize += os.path.getsize(file)\n",
    "print(f\"Will process {len(fepoutFiles)} fepout files.\\nTotal size:{np.round(totalSize/10**9, 2)}GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb3aa52-17f1-44fc-afd8-dfda2787cf32",
   "metadata": {},
   "outputs": [],
   "source": [
    "fepoutFiles = natsorted(fepoutFiles)\n",
    "maxSize = 10**9 #Don't use the alchemlyb parser if larger than this size. (bytes)\n",
    "decorrelate = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86bb2766",
   "metadata": {},
   "source": [
    "# For large data sets: read, decorrelate, save\n",
    "This reduces RAM requirements between reading and decorrelating\n",
    "\n",
    "Remember: pickles are not future-proof and should not be used for long-term data storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7b01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from alchemlyb.preprocessing import subsampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c345a68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if totalSize>maxSize:\n",
    "    method = 'dE'\n",
    "    affix = f'decorrelated_{method}'\n",
    "\n",
    "    pickles = []\n",
    "    idx = 0\n",
    "\n",
    "    for file in tqdm(fepoutFiles):\n",
    "        df = readFiles([file])\n",
    "        u_nk = u_nk_fromDF(df, temperature, 0, warnings=False)\n",
    "\n",
    "        groups = u_nk.groupby('fep-lambda')\n",
    "        decorr = pd.DataFrame([])\n",
    "        for key, group in groups:\n",
    "            test = subsampling.decorrelate_u_nk(group, method)\n",
    "            decorr = decorr.append(test)\n",
    "        u_nk = decorr\n",
    "        pickle = f\"{path}{affix}{idx:03d}.pkl\"\n",
    "        u_nk.to_pickle(pickle)\n",
    "        pickles.append(pickle)\n",
    "        idx +=1\n",
    "        \n",
    "    pickleDFs = []\n",
    "    for pickle in pickles:\n",
    "        pickleDFs.append(pd.read_pickle(pickle))\n",
    "\n",
    "    u_nk = pd.concat(pickleDFs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f812ebef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#u_nk = u_nk.drop(0.975, axis=1) #to remove incomplete windows e.g. when changing lambda resolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6f227d8",
   "metadata": {},
   "source": [
    "# Demonstration of equivalence between the above and below methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b2cfde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Demonstrate that AFEP readFiles+u_nk_fromDF is identical to namd.extract_u_nk\n",
    "## readFiles is more space efficient and can handle single files. Only reads each file once. Less input validation than alchemlyb.namd.\n",
    "#u_nk_target = namd.extract_u_nk(fepoutFiles[0:5], temperature)\n",
    "#df = readFiles(fepoutFiles[0:5])\n",
    "#u_nk_test = u_nk_fromDF(df, temperature, 10000)\n",
    "#np.all(u_nk_target.fillna(100)==u_nk_test.fillna(100))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a94bee8b",
   "metadata": {},
   "source": [
    "# Small data sets can be read and decorrelated sequentially, if desired\n",
    "See Shirts and Chodera (2008) for more details\n",
    "\n",
    "\"Statistically optimal analysis of samples from multiple equilibrium states\" doi: 10.1063/1.2978177"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab9fd1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if totalSize < maxSize:\n",
    "    from alchemlyb.preprocessing import subsampling\n",
    "\n",
    "    u_nk = namd.extract_u_nk(fepoutFiles, temperature)\n",
    "\n",
    "    if decorrelate:\n",
    "        method = 'dE'\n",
    "        affix = f'decorrelated_{method}'\n",
    "        groups = u_nk.groupby('fep-lambda')\n",
    "        decorr = pd.DataFrame([])\n",
    "        for key, group in groups:\n",
    "            test = subsampling.decorrelate_u_nk(group, method)\n",
    "            decorr = decorr.append(test)\n",
    "        u_nk = decorr\n",
    "    else:\n",
    "        affix = 'unprocessed'\n",
    "\n",
    "else:\n",
    "    print(f\"Warning: The files you are trying to read are quite large. Total size={totalSize}. Try reading and decorrelating (above) or change the maxSize parameter.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea039c3",
   "metadata": {},
   "source": [
    "# Carry out MBAR Fitting and Analyses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d681247-b508-4940-9622-2650864e2425",
   "metadata": {},
   "outputs": [],
   "source": [
    "u_nk = u_nk.sort_index(level=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c8683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "bar = BAR()\n",
    "bar.fit(u_nk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30721156",
   "metadata": {},
   "source": [
    "# Extract key features from the MBAR fitting and get Î”G\n",
    "Note: alchemlyb operates in units of kT by default. We multiply by RT to conver to units of kcal/mol."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e81f216",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, l_mid, f, df, ddf, errors = get_MBAR(bar)\n",
    "\n",
    "print(f'\\u0394G = {np.round(f.iloc[-1]*RT, 1)}\\u00B1{np.round(errors[-1], 3)} kcal/mol')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a51aba3b",
   "metadata": {},
   "source": [
    "# Plot the change in free energy based on MBAR estimates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bac26b22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cumulative change in kT\n",
    "plt.errorbar(l, f, yerr=errors, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('DeltaG(lambda) (kT)')\n",
    "plt.title(f'Cumulative dG with accumulated errors {affix}')\n",
    "plt.savefig(f'{path}dG_cumulative_kT_{affix}.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Cumulative change in kcal/mol\n",
    "plt.errorbar(l, f * RT, yerr=errors*RT, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('DeltaG(lambda)(kcal/mol)')\n",
    "plt.savefig(f'{path}dG_cumulative_kcal_per_mol_{affix}.png', dpi=600)\n",
    "plt.show()\n",
    "\n",
    "# Per-window change in kT\n",
    "plt.errorbar(l_mid, df, yerr=ddf, marker='.')\n",
    "plt.xlabel('lambda')\n",
    "plt.ylabel('Delta G per window (kT)')\n",
    "plt.title(f'Per-Window dG with individual errors {affix}')\n",
    "plt.savefig(f'{path}dG_{affix}.png', dpi=600)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7f90d8c",
   "metadata": {},
   "source": [
    "# Plot the estimated total change in free energy as a function of simulation time; contiguous subsets starting at t=0 (\"Forward\") and t=end (\"Reverse\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9351f981",
   "metadata": {},
   "outputs": [],
   "source": [
    "convergence_plot(u_nk, l)\n",
    "plt.title(f'Convergence {affix}')\n",
    "plt.savefig(f'{path}convergence_{affix}.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6709db",
   "metadata": {},
   "source": [
    "# Use an exponential estimator to assess residual discrepancies and check for hysteresis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5da24e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "l, l_mid, dG_f, dG_b = get_EXP(u_nk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b501c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.vlines(l_mid, np.zeros(len(l_mid)), dG_f + np.array(dG_b), label=\"fwd - bwd\", linewidth=2)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(f'Fwd-bwd discrepancies by lambda {affix}')\n",
    "plt.xlabel('Lambda')\n",
    "plt.ylabel('Diff. in delta-G')\n",
    "plt.savefig(f'{path}discrepancies_{affix}.png', dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eed80d8",
   "metadata": {},
   "source": [
    "# The above data should follow a roughly normal distribution centered on 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfbbeb7-3bb9-44e1-be17-72fc76afdb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy.lib.stride_tricks import sliding_window_view\n",
    "from scipy.stats import linregress as lr\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6556861-71ed-46ac-90f9-6ce63c700662",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = dG_f + np.array(dG_b)\n",
    "diff.sort()\n",
    "X = diff\n",
    "Y = np.arange(len(X))/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7f2a52-e5ae-4129-bccf-c82563869d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#fit a normal distribution to the existing data\n",
    "fitted = norm.fit(X)\n",
    "\n",
    "dx = 0.01\n",
    "Xnorm  = np.arange(np.min(X), np.max(X), dx)\n",
    "\n",
    "Ynorm = norm.cdf(Xnorm, fitted[0], fitted[1])\n",
    "Yexpected = norm.cdf(X, fitted[0], fitted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fe07c8-1332-43ea-8393-1dd5c027150c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the coefficient of determination:\n",
    "def GetRsq(X, Y, Yexpected):\n",
    "    residuals = Y-Yexpected\n",
    "    SSres = np.sum(residuals**2)\n",
    "    SStot = np.sum((X-np.mean(X))**2)\n",
    "    R = 1-SSres/SStot\n",
    "    R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f76120d3-cb60-4ecd-8c46-0e98b3ef3085",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Estimate the probability density distribution from the moving slope of a CDF. i.e. using the values X and their cumulative density FX\n",
    "def getMovingAveSlope(X,FX,window):\n",
    "    slopes = []\n",
    "    Xwindowed = sliding_window_view(X, window)\n",
    "    FXwindowed = sliding_window_view(FX, window)\n",
    "   \n",
    "    for i in np.arange(len(Xwindowed)):\n",
    "        Xwindow = Xwindowed[i]\n",
    "        FXwindow = FXwindowed[i]\n",
    "        result = lr(Xwindow, FXwindow)\n",
    "        m = result.slope\n",
    "        slopes.append(m)\n",
    "    return slopes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88943b75-4c3f-4149-a58a-9284fff9957f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "#plot the data as they are (estimate the CDF) and the fitted cdf\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "plt.xlabel(\"dG_f+dG_b\")\n",
    "plt.ylabel(\"CDF\")\n",
    "plt.title(\"Distribution of differences between forward and backward calculations\")\n",
    "axins = inset_axes(ax, width=\"30%\", height=1., loc=2, borderpad=4)\n",
    "\n",
    "axins2 = inset_axes(ax, width=\"40%\", height=\"20%\", loc=4, borderpad=1)\n",
    "\n",
    "# Turn ticklabels of insets off\n",
    "for axi in [axins, axins2]:\n",
    "    axi.tick_params(labelleft=False, labelbottom=False)\n",
    "\n",
    "ax.scatter(X, Y, 2, label=\"Fwd bkd differences\")\n",
    "ax.plot(Xnorm, Ynorm, label=\"Normal Distribution\", color=\"orange\")\n",
    "\n",
    "residuals = Y-Yexpected\n",
    "axins2.plot(X, residuals)\n",
    "\n",
    "\n",
    "binNum = 20\n",
    "axins.hist(dG_f + np.array(dG_b), bins=binNum, density=True);\n",
    "#axins.title(f'Density Distribution of fwd-bwd discrepancies {affix}')\n",
    "#axins.xlabel('Difference in delta-G')\n",
    "#axins.ylabel('Density')\n",
    "#plt.savefig(f'{path}distribution_{affix}.png', dpi=600)\n",
    "\n",
    "window = binNum\n",
    "dydx = getMovingAveSlope(X, Y, window)\n",
    "e = int(window/2)\n",
    "axins.plot(X[e:-e], dydx[:-1], color=\"gray\")\n",
    "\n",
    "ax.legend()\n",
    "\n",
    "plt.savefig(f\"{path}DistributionOfDifferences{affix}.png\", dpi=600)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b24e57b-3bb8-4f9e-ba1e-e04d9787b699",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
